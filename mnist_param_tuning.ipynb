{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador KNN - Encontrando parâmetros para a base de dados MNIST\n",
    "\n",
    "Estamos interessados em melhorar a performance do nosso classificador KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obter o data set de imagens\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Biblioteca numpy\n",
    "import numpy as np\n",
    "# Classificador KNN\n",
    "from classifiers.neighbors import KNeighborsClassifier\n",
    "# Para medir o tempo de execução dos algoritmos\n",
    "from ext.timer import elapsed_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo o data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, utilizamos a biblioteca _tensorflow_ para obter o data set MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('datasets/MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o tamanho do data set:\n",
    "TAMANHO = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.asarray(mnist.train.images[:TAMANHO])\n",
    "train_labels = np.asarray(mnist.train.labels[:TAMANHO])\n",
    "test_images = np.asarray(mnist.test.images)\n",
    "test_labels = np.asarray(mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação\n",
    "\n",
    "### Definindo uma função que exibe os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_resultados(test_images, pred):\n",
    "    i = 0\n",
    "    total_correct = 0\n",
    "    for test_image in test_images:\n",
    "        if pred[i] == test_labels[i]:\n",
    "            total_correct += 1\n",
    "        acc = (total_correct / (i+1)) * 100\n",
    "        print('test image['+str(i)+']', '\\tpred:', pred[i], '\\torig:', test_labels[i], '\\tacc:', str(round(acc, 2))+'%')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificando imagens \n",
    "\n",
    "#### Algoritmo KD-Tree\n",
    "\n",
    "A seguir instanciamos o nosso classificador knn com o algoritmo _kd-tree_. Iremos tentar obter a melhor acurácia possível apenas com o tamanho de folha igual a 30. Modificaremos as medidas de distância, o número de vizinhos a serem analisados, entre outros parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 3, dist_metric = euclidean, weights = uniform\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=3, algorithm='kd_tree')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 5, dist_metric = euclidean, weights = uniform\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=5, algorithm='kd_tree')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 7, dist_metric = euclidean, weights = uniform\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=7, algorithm='kd_tree')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 9, dist_metric = euclidean, weights = uniform\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=9, algorithm='kd_tree')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 3, dist_metric = manhattan, weights = uniform\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=3, \n",
    "                                      algorithm='kd_tree', dist_metric='manhattan')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 3, dist_metric = chebyshev, weights = uniform\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=3, \n",
    "                                      algorithm='kd_tree', dist_metric='chebyshev')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 3, dist_metric = euclidean, weights = distance\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=3,\n",
    "                                      algorithm='kd_tree', weights='distance')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 5, dist_metric = euclidean, weights = distance\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=5, \n",
    "                                      algorithm='kd_tree', weights='distance')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf size = 30, n_neighbors = 7, dist_metric = euclidean, weights = distance\n",
    "\n",
    "with elapsed_timer() as elapsed:\n",
    "    classifier = KNeighborsClassifier(leaf_size=30, n_neighbors=7, \n",
    "                                      algorithm='kd_tree', weights='distance')\n",
    "    classifier.fit(train_images, train_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Tempo de execução: \" + str(elapsed()))\n",
    "\n",
    "mostrar_resultados(test_images, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Através dos nossos testes, percebemos que os parametros\n",
    "- Leaf size = 30\n",
    "- n_neighbors = 3\n",
    "- dist_metric = euclidean\n",
    "- weights = distance\n",
    "fornecem pistas de bons parâmetros para obter uma melhor acurácia na predição de dígitos da base de dados MNIST, utilizando nosso classificador. \n",
    "\n",
    "É claro que deixamos nosso data set apenas com 2000 instâncias, por motivos de memória e tempo, além de termos definido o tamanho da folha como 30, já que quanto maior a folha, mais tempo é necessário para calcular a distância entre vizinhos (o algoritmo executa uma busca em força bruta dos vizinhos mais próximos na folha encontrada).\n",
    "\n",
    "Note ainda que nosso classificador tem um desempenho muito inferior ao algoritmo do sk learn por exemplo, mas é interessante notar como a mudança de alguns parâmetros afetam o desenpenho do classificador, em especial o número de vizinhos a serem analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
